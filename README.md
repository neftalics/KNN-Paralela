# ParalelizaciÃ³n de KNN con MPI

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![MPI](https://img.shields.io/badge/MPI-mpi4py-green.svg)](https://mpi4py.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

ImplementaciÃ³n paralela del algoritmo **K-Nearest Neighbors (KNN)** utilizando **MPI (Message Passing Interface)** en Python. Este proyecto demuestra tÃ©cnicas de paralelizaciÃ³n para algoritmos de Machine Learning mediante el modelo SPMD (Single Program, Multiple Data).

## ğŸ‘¥ Autores

- **FabiÃ¡n Alvarado Ramos**
- **Eduardo Miguel Salas Palacios**
- **NeftalÃ­ Calixto Rojas**

**InstituciÃ³n:** Proyecto Universitario de ComputaciÃ³n Paralela

---

## ğŸ“‹ DescripciÃ³n del Proyecto

El algoritmo KNN tiene una complejidad computacional de O(NÃ—M), donde N es el nÃºmero de puntos de entrenamiento y M el nÃºmero de puntos de prueba. Este proyecto paraleliza el cÃ¡lculo de distancias distribuyendo los puntos de prueba entre mÃºltiples procesos usando MPI.

### CaracterÃ­sticas Principales

- âœ… ImplementaciÃ³n secuencial de referencia
- âœ… Tres versiones incrementales (Beta 1, Beta 2, Final)
- âœ… Modelo maestro-trabajador con topologÃ­a DAG
- âœ… Operaciones colectivas MPI: `scatter`, `bcast`, `gather`
- âœ… AnÃ¡lisis completo de rendimiento (Speedup, Eficiencia, FLOPs)
- âœ… Escalabilidad con tamaÃ±o variable del problema

---

## ğŸ“ Estructura del Repositorio

```
Paralela-Proyecto/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ knn_sequential.py         # VersiÃ³n secuencial (baseline)
â”‚   â”œâ”€â”€ knn_parallel_v1.py        # Beta 1: ComunicaciÃ³n bÃ¡sica
â”‚   â”œâ”€â”€ knn_parallel_v2.py        # Beta 2: CÃ³mputo distribuido
â”‚   â”œâ”€â”€ knn_parallel_final.py     # VersiÃ³n final optimizada
â”‚   â””â”€â”€ knn_parallel_synthetic.py # VersiÃ³n con datos sintÃ©ticos
â”‚
â”œâ”€â”€ analysis/                     # Scripts de anÃ¡lisis
â”‚   â”œâ”€â”€ run_experiments.py        # Experimentos con variaciÃ³n de p
â”‚   â”œâ”€â”€ run_scaling_experiments.py# Experimentos con variaciÃ³n de N
â”‚   â”œâ”€â”€ plot_results.py           # GrÃ¡ficas (tema oscuro)
â”‚   â””â”€â”€ plot_results_white.py     # GrÃ¡ficas (tema blanco)
â”‚
â”œâ”€â”€ docs/                         # DocumentaciÃ³n
â”‚   â”œâ”€â”€ reporte_proyecto.tex      # Reporte acadÃ©mico (LaTeX)
â”‚   â”œâ”€â”€ presentacion_beamer.tex   # PresentaciÃ³n (Beamer)
â”‚   â”œâ”€â”€ images/                   # GrÃ¡ficas tema oscuro
â”‚   â””â”€â”€ images_report/            # GrÃ¡ficas tema blanco
â”‚
â”œâ”€â”€ results_log.csv               # Resultados experimentales (p variable)
â”œâ”€â”€ scaling_log.csv               # Resultados de escalabilidad (N variable)
â””â”€â”€ README.md                     # Este archivo
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- **Python 3.8+**
- **MPI Implementation:**
  - Windows: [MS-MPI](https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi)
  - Linux/Mac: OpenMPI o MPICH

### Dependencias de Python

```bash
pip install mpi4py numpy scikit-learn matplotlib pandas
```

### Verificar InstalaciÃ³n de MPI

```bash
mpiexec --version
```

---

## ğŸ’» Uso

### 1. EjecuciÃ³n Secuencial (Baseline)

```bash
python src/knn_sequential.py
```

**Salida esperada:**
```
Accuracy (Sequential): 0.9833
Execution Time: 5.02 seconds
```

### 2. EjecuciÃ³n Paralela

#### Con 4 procesos:
```bash
mpiexec -n 4 python src/knn_parallel_final.py
```

#### Con 8 procesos:
```bash
mpiexec -n 8 python src/knn_parallel_final.py
```

**Salida esperada (Rank 0):**
```
=== KNN Parallel (Final Version) ===
Processes: 4
Accuracy: 0.9833
Total Time: 2.09 seconds
Compute Time: 1.85 seconds
Communication Time: 0.24 seconds
Speedup: 2.40x
Efficiency: 60.0%
```

### 3. Ejecutar Experimentos Completos

#### VariaciÃ³n del nÃºmero de procesos (p âˆˆ {1,2,4,8}):
```bash
python analysis/run_experiments.py
```

#### VariaciÃ³n del tamaÃ±o del dataset (N variable):
```bash
python analysis/run_scaling_experiments.py
```

### 4. Generar GrÃ¡ficas

#### GrÃ¡ficas con tema oscuro (presentaciÃ³n):
```bash
python analysis/plot_results.py
```

#### GrÃ¡ficas con fondo blanco (reporte):
```bash
python analysis/plot_results_white.py
```

**GrÃ¡ficas generadas:**
- `time_vs_processes.png` - AnÃ¡lisis de tiempos
- `speedup.png` - AceleraciÃ³n vs ideal
- `efficiency.png` - Eficiencia del clÃºster
- `flops.png` - Rendimiento computacional
- `scalability_n.png` - Escalabilidad con N

---

## ğŸ“Š Resultados Principales

### Dataset Utilizado
- **Nombre:** Digits (scikit-learn)
- **CaracterÃ­sticas:** ImÃ¡genes 8Ã—8 pÃ­xeles (64 dimensiones)
- **Muestras totales:** 1797
- **Train/Test split:** 80/20 (1437 train, 360 test)
- **Clases:** 10 (dÃ­gitos 0-9)

### MÃ©tricas de Rendimiento

| Procesos | Tiempo (s) | Speedup | Eficiencia | FLOPs/s |
|----------|------------|---------|------------|---------|
| 1        | 5.02       | 1.00x   | 100%       | 19.8M   |
| 2        | 2.68       | 1.87x   | 94%        | 37.1M   |
| 4        | 2.09       | 2.40x   | 60%        | 47.6M   |
| 8        | 2.01       | 2.50x   | 31%        | 49.5M   |

### Hallazgos Clave

- âœ… **PrecisiÃ³n idÃ©ntica:** 0.9833 (secuencial vs paralelo)
- âœ… **ReducciÃ³n de tiempo:** 60% (5.02s â†’ 2.01s)
- âœ… **ConfiguraciÃ³n Ã³ptima:** 4 procesos (mejor balance speedup/eficiencia)
- âš ï¸ **SaturaciÃ³n:** A partir de 8 procesos, el overhead de comunicaciÃ³n domina
- ğŸ“ˆ **Complejidad confirmada:** O(NÂ²) verificada experimentalmente

---

## ğŸ”¬ MetodologÃ­a

### Arquitectura Maestro-Trabajador

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main   â”‚  (Rank 0: Scatter datos)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
  â”Œâ”€â”€â”´â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
  â”‚     â”‚      â”‚      â”‚
â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â”
â”‚ T1â”‚ â”‚ T2â”‚ â”‚ T3â”‚ â”‚ T4â”‚  (Workers: CÃ³mputo local)
â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜
  â”‚     â”‚      â”‚      â”‚
  â””â”€â”€â”¬â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
     â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚   End   â”‚  (Rank 0: Gather resultados)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Operaciones MPI Utilizadas

1. **`MPI_Scatter`**: Distribuir X_test entre procesos
2. **`MPI_Bcast`**: Enviar X_train, y_train a todos
3. **`MPI_Gather`**: Recolectar predicciones parciales

### CÃ¡lculo de FLOPs

Distancia euclidiana: `d(x,y) = âˆš(Î£(xáµ¢-yáµ¢)Â²)`

- **FLOPs por distancia:** 3d (d restas + d multiplicaciones + d sumas)
- **FLOPs totales:** M Ã— N Ã— 3d = 360 Ã— 1437 Ã— 192 â‰ˆ **99.5 MFLOPs**

---

## ğŸ“– DocumentaciÃ³n

### Reporte AcadÃ©mico

El reporte completo en LaTeX se encuentra en `docs/reporte_proyecto.tex` e incluye:

- âœ… IntroducciÃ³n y justificaciÃ³n
- âœ… Modelo PRAM y topologÃ­a DAG
- âœ… Desarrollo incremental (3 versiones beta)
- âœ… AnÃ¡lisis de complejidad teÃ³rica normalizada
- âœ… Resultados experimentales completos
- âœ… DerivaciÃ³n de FLOPs desde distancia euclidiana
- âœ… AnÃ¡lisis de escalabilidad
- âœ… Conclusiones y mejoras propuestas
- âœ… BibliografÃ­a con impacto descrito

### Compilar el Reporte

```bash
cd docs
pdflatex reporte_proyecto.tex
```

---

## ğŸ¯ Mejoras Futuras

1. **OptimizaciÃ³n de ComunicaciÃ³n:** Usar comunicaciÃ³n punto a punto para datasets grandes
2. **Estructuras de Datos Avanzadas:** Implementar KD-trees o Ball Trees
3. **ParalelizaciÃ³n HÃ­brida:** Combinar MPI + OpenMP
4. **Balanceo DinÃ¡mico:** DistribuciÃ³n adaptativa de carga
5. **GPU Acceleration:** Porting a CUDA/OpenCL

---

## ğŸ“š Referencias

1. **MPI Forum**. "MPI: A Message-Passing Interface Standard". Version 4.0, 2021.
2. **Gropp, W., Lusk, E., & Skjellum, A.** "Using MPI: Portable Parallel Programming with the Message-Passing Interface". MIT Press, 2014.
3. **mpi4py Documentation**. https://mpi4py.readthedocs.io/
4. **Scikit-learn**. "K-Nearest Neighbors". https://scikit-learn.org/stable/modules/neighbors.html
5. **Pacheco, P.** "An Introduction to Parallel Programming". Morgan Kaufmann, 2011.

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

---

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico. Para preguntas o sugerencias, contactar a los autores.

---

## ğŸ“ Contacto

**Repositorio:** https://github.com/neftalics/KNN-Paralela

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
